{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing Example\n",
    "\n",
    "In this example, we use the `micasense.imageset` class to load a set of directories of images into a list of `micasense.capture` objects, and we iterate over that list saving out each image as an aligned stack of images as separate bands in a single tiff file each. Next, we use the metadata from the original captures to write out a log file of the captures and their locations.  Finally, we use `exiftool` from the command line to inject that metadata into the processed images, allowing us to stitch those images using commercial software such as Pix4D or Agisoft.\n",
    "\n",
    "Note: for this example to work, the images must have a valid RigRelatives tag. This requires RedEdge version of at least 3.4.0 or any version of Altum.  If your images don't meet that spec, you can also follow this support ticket to add the RigRelatives tag to them: https://support.micasense.com/hc/en-us/articles/360006368574-Modifying-older-collections-for-Pix4Dfields-support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images into ImageSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress, Layout\n",
    "from IPython.display import display\n",
    "import micasense.imageset as imageset\n",
    "import micasense.capture as capture\n",
    "import os, glob\n",
    "import multiprocessing\n",
    "\n",
    "panelNames = None\n",
    "useDLS = True\n",
    "\n",
    "imagePath = os.path.expanduser(os.path.join('.','data','0000SET'))\n",
    "panelNames = glob.glob(os.path.join(imagePath,'000','IMG_0005_*.tif'))\n",
    "panelCap = capture.Capture.from_filelist(panelNames)\n",
    "\n",
    "outputPath = os.path.join(imagePath,'..','stacks')\n",
    "thumbnailPath = os.path.join(outputPath, '..', 'thumbnails')\n",
    "\n",
    "overwrite = False # can be set to set to False to continue interrupted processing\n",
    "generateThumbnails = True\n",
    "\n",
    "# Allow this code to align both radiance and reflectance images; bu excluding\n",
    "# a definition for panelNames above, radiance images will be used\n",
    "# For panel images, efforts will be made to automatically extract the panel information\n",
    "# but if the panel/firmware is before Altum 1.3.5, RedEdge 5.1.7 the panel reflectance\n",
    "# will need to be set in the panel_reflectance_by_band variable.\n",
    "# Note: radiance images will not be used to properly create NDVI/NDRE images below.\n",
    "if panelNames is not None:\n",
    "    panelCap = capture.Capture.from_filelist(panelNames)\n",
    "else:\n",
    "    panelCap = None\n",
    "\n",
    "if panelCap is not None:\n",
    "    if panelCap.panel_albedo() is not None and not any(v is None for v in panelCap.panel_albedo()):\n",
    "        panel_reflectance_by_band = panelCap.panel_albedo()\n",
    "    else:\n",
    "        panel_reflectance_by_band = [0.67, 0.69, 0.68, 0.61, 0.67] #RedEdge band_index order\n",
    "    \n",
    "    panel_irradiance = panelCap.panel_irradiance(panel_reflectance_by_band)    \n",
    "    img_type = \"reflectance\"\n",
    "else:\n",
    "    if useDLS:\n",
    "        img_type='reflectance'\n",
    "    else:\n",
    "        img_type = \"radiance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b568db96d31f4342b31ea08a0b66a6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, description='Loading', layout=Layout(width='100%'), max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vinu.d/Documents/Projects/repos/VinuUD/imageprocessing/micasense/imageset.py:138: PendingDeprecationWarning: The progress_callback parameter will be deprecated in favor of use_tqdm\n",
      "  warnings.warn(message='The progress_callback parameter will be deprecated in favor of use_tqdm',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageSet from: ./data/0000SET\n",
      "CPU times: user 29.9 ms, sys: 10.8 ms, total: 40.7 ms\n",
      "Wall time: 426 ms\n"
     ]
    }
   ],
   "source": [
    "## This progress widget is used for display of the long-running process\n",
    "f = FloatProgress(min=0, max=1, layout=Layout(width='100%'), description=\"Loading\")\n",
    "display(f)\n",
    "def update_f(val):\n",
    "    if (val - f.value) > 0.005 or val == 1: #reduces cpu usage from updating the progressbar by 10x\n",
    "        f.value=val\n",
    "\n",
    "%time imgset = imageset.ImageSet.from_directory(imagePath, progress_callback=update_f)\n",
    "update_f(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/mapboxgl/viz.py:5: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of class have to be an integer greater than or equal to 1 and smaller than or equal to the number of unique values to use",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m max_val \u001b[39m=\u001b[39m df[color_property]\u001b[39m.\u001b[39mmax()\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjenkspy\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m breaks \u001b[39m=\u001b[39m jenkspy\u001b[39m.\u001b[39;49mjenks_breaks(df[color_property], n_classes\u001b[39m=\u001b[39;49mnum_color_classes)\n\u001b[1;32m     22\u001b[0m color_stops \u001b[39m=\u001b[39m create_color_stops(breaks,colors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mYlOrRd\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m geojson_data \u001b[39m=\u001b[39m df_to_geojson(df,columns[\u001b[39m3\u001b[39m:],lat\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlatitude\u001b[39m\u001b[39m'\u001b[39m,lon\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlongitude\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/jenkspy/core.py:212\u001b[0m, in \u001b[0;36mjenks_breaks\u001b[0;34m(values, n_classes)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjenks_breaks\u001b[39m(values: Sequence[\u001b[39mfloat\u001b[39m], n_classes: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m    183\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39m    Compute natural breaks (Fisher-Jenks algorithm) on a sequence of `values`,\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m    given `n_classes`, the number of desired class.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    210\u001b[0m \n\u001b[1;32m    211\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     n_classes \u001b[39m=\u001b[39m validate_input(values, n_classes)\n\u001b[1;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m jenks\u001b[39m.\u001b[39m_jenks_breaks(values, n_classes)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/jenkspy/core.py:176\u001b[0m, in \u001b[0;36mvalidate_input\u001b[0;34m(values, n_classes)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39m# Check that the number of classes is lesser than or equal to the length of unique values\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39m# and greater than or equal to 1\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m n_classes \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(values)) \u001b[39mor\u001b[39;00m n_classes \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 176\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumber of class have to be an integer greater than or equal to 1 and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39msmaller than or equal to the number of unique values to use\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    179\u001b[0m \u001b[39mreturn\u001b[39;00m n_classes\n",
      "\u001b[0;31mValueError\u001b[0m: Number of class have to be an integer greater than or equal to 1 and smaller than or equal to the number of unique values to use"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from mapboxgl.viz import *\n",
    "from mapboxgl.utils import df_to_geojson, create_radius_stops, scale_between\n",
    "from mapboxgl.utils import create_color_stops\n",
    "import pandas as pd\n",
    "\n",
    "data, columns = imgset.as_nested_lists()\n",
    "df = pd.DataFrame.from_records(data, index='timestamp', columns=columns)\n",
    "\n",
    "#Insert your mapbox token here\n",
    "token = 'pk.eyJ1IjoibWljYXNlbnNlIiwiYSI6ImNqYWx5dWNteTJ3cWYzMnBicmZid3g2YzcifQ.Zrq9t7GYocBtBzYyT3P4sw'\n",
    "color_property = 'dls-yaw'\n",
    "num_color_classes = 8\n",
    "\n",
    "min_val = df[color_property].min()\n",
    "max_val = df[color_property].max()\n",
    "\n",
    "import jenkspy\n",
    "breaks = jenkspy.jenks_breaks(df[color_property], n_classes=num_color_classes)\n",
    "\n",
    "color_stops = create_color_stops(breaks,colors='YlOrRd')\n",
    "geojson_data = df_to_geojson(df,columns[3:],lat='latitude',lon='longitude')\n",
    "\n",
    "viz = CircleViz(geojson_data, access_token=token, color_property=color_property,\n",
    "                color_stops=color_stops,\n",
    "                center=[df['longitude'].median(),df['latitude'].median()], \n",
    "                zoom=16, height='600px',\n",
    "                style='mapbox://styles/mapbox/satellite-streets-v9')\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define which warp method to use\n",
    "For newer data sets with RigRelatives tags (images captured with RedEdge version 3.4.0 or greater with a valid calibration load, see https://support.micasense.com/hc/en-us/articles/360005428953-Updating-RedEdge-for-Pix4Dfields), we can use the RigRelatives for a simple alignment.\n",
    "\n",
    "For sets without those tags, or sets that require a RigRelatives optimization, we can go through the Alignment.ipynb notebook and get a set of `warp_matrices` that we can use here to align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import float32\n",
    "\n",
    "# Set warp_matrices to none to align using RigRelatives\n",
    "# Or\n",
    "# Use the warp_matrices derived from the Alignment Tutorial for this RedEdge set without RigRelatives\n",
    "warp_matrices = [array([[ 1.0022864e+00, -2.5218755e-03, -7.8898020e+00],\n",
    "       [ 2.3614739e-03,  1.0036649e+00, -1.3134377e+01],\n",
    "       [-1.7785899e-06,  1.1343118e-06,  1.0000000e+00]], dtype=float32), array([[1., 0., 0.],\n",
    "       [0., 1., 0.],\n",
    "       [0., 0., 1.]], dtype=float32), array([[ 9.9724638e-01, -1.5535230e-03,  1.2301294e+00],\n",
    "       [ 8.6745428e-04,  9.9738181e-01, -1.6499169e+00],\n",
    "       [-8.2816513e-07, -3.4488804e-07,  1.0000000e+00]], dtype=float32), array([[ 1.0007139e+00, -8.4427800e-03,  1.6312805e+01],\n",
    "       [ 6.2834378e-03,  9.9977130e-01, -1.6011697e+00],\n",
    "       [-1.9520389e-06, -6.3762940e-07,  1.0000000e+00]], dtype=float32), array([[ 9.9284178e-01,  9.2155562e-04,  1.6069822e+01],\n",
    "       [-3.2895457e-03,  9.9262553e-01, -5.0333548e-01],\n",
    "       [-1.5845577e-06, -1.7680986e-06,  1.0000000e+00]], dtype=float32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align images and save each capture to a layered tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749300acc2854ad9b9894fdc71b3c907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, description='Saving', layout=Layout(width='100%'), max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'geojson_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# Save out geojson data so we can open the image capture locations in our GIS\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(outputPath,\u001b[39m'\u001b[39m\u001b[39mimageSet.json\u001b[39m\u001b[39m'\u001b[39m),\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 16\u001b[0m     f\u001b[39m.\u001b[39mwrite(\u001b[39mstr\u001b[39m(geojson_data))\n\u001b[1;32m     18\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     irradiance \u001b[39m=\u001b[39m panel_irradiance\u001b[39m+\u001b[39m[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'geojson_data' is not defined"
     ]
    }
   ],
   "source": [
    "import exiftool\n",
    "import datetime\n",
    "## This progress widget is used for display of the long-running process\n",
    "f2 = FloatProgress(min=0, max=1, layout=Layout(width='100%'), description=\"Saving\")\n",
    "display(f2)\n",
    "def update_f2(val):\n",
    "    f2.value=val\n",
    "\n",
    "if not os.path.exists(outputPath):\n",
    "    os.makedirs(outputPath)\n",
    "if generateThumbnails and not os.path.exists(thumbnailPath):\n",
    "    os.makedirs(thumbnailPath)\n",
    "\n",
    "# Save out geojson data so we can open the image capture locations in our GIS\n",
    "with open(os.path.join(outputPath,'imageSet.json'),'w') as f:\n",
    "    f.write(str(geojson_data))\n",
    "    \n",
    "try:\n",
    "    irradiance = panel_irradiance+[0]\n",
    "except NameError:\n",
    "    irradiance = None\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "for i,capture in enumerate(imgset.captures):\n",
    "    outputFilename = capture.uuid+'.tif'\n",
    "    thumbnailFilename = capture.uuid+'.jpg'\n",
    "    fullOutputPath = os.path.join(outputPath, outputFilename)\n",
    "    fullThumbnailPath= os.path.join(thumbnailPath, thumbnailFilename)\n",
    "    if (not os.path.exists(fullOutputPath)) or overwrite:\n",
    "        if(len(capture.images) == len(imgset.captures[0].images)):\n",
    "            capture.create_aligned_capture(irradiance_list=irradiance, warp_matrices=warp_matrices)\n",
    "            capture.save_capture_as_stack(fullOutputPath)\n",
    "            if generateThumbnails:\n",
    "                capture.save_capture_as_rgb(fullThumbnailPath)\n",
    "    capture.clear_image_data()\n",
    "    update_f2(float(i)/float(len(imgset.captures)))\n",
    "update_f2(1.0)\n",
    "end = datetime.datetime.now()\n",
    "\n",
    "print(\"Saving time: {}\".format(end-start))\n",
    "print(\"Alignment+Saving rate: {:.2f} images per second\".format(float(len(imgset.captures))/float((end-start).total_seconds())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Metadata from Captures list and save to log.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decdeg2dms(dd):\n",
    "   is_positive = dd >= 0\n",
    "   dd = abs(dd)\n",
    "   minutes,seconds = divmod(dd*3600,60)\n",
    "   degrees,minutes = divmod(minutes,60)\n",
    "   degrees = degrees if is_positive else -degrees\n",
    "   return (degrees,minutes,seconds)\n",
    "\n",
    "header = \"SourceFile,\\\n",
    "GPSDateStamp,GPSTimeStamp,\\\n",
    "GPSLatitude,GpsLatitudeRef,\\\n",
    "GPSLongitude,GPSLongitudeRef,\\\n",
    "GPSAltitude,GPSAltitudeRef,\\\n",
    "FocalLength,\\\n",
    "XResolution,YResolution,ResolutionUnits\\n\"\n",
    "\n",
    "lines = [header]\n",
    "for capture in imgset.captures:\n",
    "    #get lat,lon,alt,time\n",
    "    outputFilename = capture.uuid+'.tif'\n",
    "    fullOutputPath = os.path.join(outputPath, outputFilename)\n",
    "    lat,lon,alt = capture.location()\n",
    "    #write to csv in format:\n",
    "    # IMG_0199_1.tif,\"33 deg 32' 9.73\"\" N\",\"111 deg 51' 1.41\"\" W\",526 m Above Sea Level\n",
    "    latdeg, latmin, latsec = decdeg2dms(lat)\n",
    "    londeg, lonmin, lonsec = decdeg2dms(lon)\n",
    "    latdir = 'North'\n",
    "    if latdeg < 0:\n",
    "        latdeg = -latdeg\n",
    "        latdir = 'South'\n",
    "    londir = 'East'\n",
    "    if londeg < 0:\n",
    "        londeg = -londeg\n",
    "        londir = 'West'\n",
    "    resolution = capture.images[0].focal_plane_resolution_px_per_mm\n",
    "\n",
    "    linestr = '\"{}\",'.format(fullOutputPath)\n",
    "    linestr += capture.utc_time().strftime(\"%Y:%m:%d,%H:%M:%S,\")\n",
    "    linestr += '\"{:d} deg {:d}\\' {:.2f}\"\" {}\",{},'.format(int(latdeg),int(latmin),latsec,latdir[0],latdir)\n",
    "    linestr += '\"{:d} deg {:d}\\' {:.2f}\"\" {}\",{},{:.1f} m Above Sea Level,Above Sea Level,'.format(int(londeg),int(lonmin),lonsec,londir[0],londir,alt)\n",
    "    linestr += '{}'.format(capture.images[0].focal_length)\n",
    "    linestr += '{},{},mm'.format(resolution,resolution)\n",
    "    linestr += '\\n' # when writing in text mode, the write command will convert to os.linesep\n",
    "    lines.append(linestr)\n",
    "\n",
    "fullCsvPath = os.path.join(outputPath,'log.csv')\n",
    "with open(fullCsvPath, 'w') as csvfile: #create CSV\n",
    "    csvfile.writelines(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Exiftool from the command line to write metadata to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exiftool -csv=\"./data/0000SET/../stacks/log.csv\" -overwrite_original ./data/0000SET/../stacks\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'exiftool -csv=\"./data/0000SET/../stacks/log.csv\" -overwrite_original ./data/0000SET/../stacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m cmd \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m -csv=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m -overwrite_original \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(exiftool_cmd, fullCsvPath, outputPath)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(cmd)\n\u001b[0;32m---> 10\u001b[0m subprocess\u001b[39m.\u001b[39;49mcheck_call(cmd)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:408\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_call\u001b[39m(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    399\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run command with arguments.  Wait for command to complete.  If\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[39m    the exit code was zero then return, otherwise raise\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[39m    CalledProcessError.  The CalledProcessError object will have the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[39m    check_call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m     retcode \u001b[39m=\u001b[39m call(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    409\u001b[0m     \u001b[39mif\u001b[39;00m retcode:\n\u001b[1;32m    410\u001b[0m         cmd \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:389\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39m*\u001b[39mpopenargs, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    382\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run command with arguments.  Wait for command to complete or\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m    timeout, then return the returncode attribute.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39m    retcode = call([\"ls\", \"-l\"])\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m p:\n\u001b[1;32m    390\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m             \u001b[39mreturn\u001b[39;00m p\u001b[39m.\u001b[39mwait(timeout\u001b[39m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[1;32m   1032\u001b[0m                         restore_signals,\n\u001b[1;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[1;32m   1035\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:1950\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[39mif\u001b[39;00m errno_num \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1949\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1950\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1951\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'exiftool -csv=\"./data/0000SET/../stacks/log.csv\" -overwrite_original ./data/0000SET/../stacks'"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "if os.environ.get('exiftoolpath') is not None:\n",
    "    exiftool_cmd = os.path.normpath(os.environ.get('exiftoolpath'))\n",
    "else:\n",
    "    exiftool_cmd = 'exiftool'\n",
    "        \n",
    "cmd = '{} -csv=\"{}\" -overwrite_original {}'.format(exiftool_cmd, fullCsvPath, outputPath)\n",
    "print(cmd)\n",
    "subprocess.check_call(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
